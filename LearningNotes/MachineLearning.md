Machine Learning Notes

* **Principal Component Analysis (PCA)**

Given: feature vectors \bm{x_1, x_2, ...,x_n} \in \mathbb{R}^d
![A Matrix](http://bit.ly/22jA4OG) find the top k eigenvectors/eigenvalues of ![eig](http://bit.ly/1TzbAPa) Project each ![phi](http://bit.ly/22jAJzE)


Goal: feature transformation \Phi : \mathbb{R}^d \rightarrow \mathbb{R}^k
* **Single Value Decomposition (SVD)**

